== Common problems and their solutions

=== System file encoding

Most Java tools use the system file encoding when no specific encoding is specified.
This means that running the same build on machines with different file encoding can yield different outputs.
Gradle currently does only track that no file encoding has been specified on a task basis - but it does not track the system encoding of the JVM it is using.
This can cause incorrect builds. You should always set the file system encoding to avoid these kind of problems.

=== Environment variable tracking

Gradle does currently not track environment variables for tasks.
For example for the `Test` tasks it is completely possible that the outcome depends on a few environment variables.
To ensure that only the right artifacts are re-used between builds you need to add environment variables as an input to the tasks depending on them.

Absolute paths are often passed as environment variables, too. You need to pay attention what you add as an input to the task in this case. If you add the absolute path then it will be very hard to re-use task outputs between different machines.
You would need to ensure that the absolute path is the same between machines. Most times it makes sense to track the file or the contents of the directory the absolute path points to.
If the absolute path represents a tool being used it probably makes sense to track the tool version as an input instead.

If you are adding conditional logic whether you are building on CI or on a developer machine make sure that this does not break loading task outputs on developer machines from CI.
For example, the following setup would break caching of `Test` tasks, since Gradle always would detect the difference in custom task actions:

[source, groovy]
if (System.getenv().containsKey("CI") {
    test.doFirst {
            println "Running test on CI"
        }
    }
}

You should always add the action unconditionally:

[source, groovy]
test.doFirst {
    if (System.getenv().containsKey("CI") {
            println "Running test on CI"
        }
    }
}

This way, both the task has the same custom action on CI and on developer builds and its outputs can be re-used if the remaining inputs are the same.

=== Line endings

If you are building on different operating systems be aware that some version control systems convert line endings on check-out.
For example git on Windows by default uses `autocrlf=true` which converts all line endings to `\r\n`.
As a consequence, compilation outputs can't be re-used on Windows since the input sources are different.
You should make sure that `autocrlf=false` across your build machines to ensure optimal build cache usage.

=== Symbolic links

Gradle does not store the symbolic link in the build cache but the actual file contents of the destination of the link.
As a consequence you might have a hard time when trying to re-use outputs which heavily use symbolic links.
There currently is no workaround for this behavior.

[[java_version_tracking]]
=== Java version tracking

Gradle does track the major version of Java as an input for compilation and test execution.
Currently, it does neither track the vendor nor the minor version.
Still, the vendor and the minor version may influence the bytecode produced by compilation.

If you use different JVM vendors for compiling or running Java we strongly suggest that you add the vendor as an input to the corresponding tasks.
This can be achieved by using the {user-manual}more_about_tasks.html#sec:task_input_output_runtime_api[runtime API] as shown in the following snippet.

[source,groovy]
------------------
tasks.withType(AbstractCompile) {
    inputs.property("java.vendor") {
        System.getProperty("java.vendor")
    }
}

tasks.withType(Test) {
    inputs.property("java.vendor") {
        System.getProperty("java.vendor")
    }
}
------------------

With respect to tracking the Java minor version there are different competing aspects: support pulling results for developers and having "perfect" results on CI. There are basically two situations when you may want to track the minor version number of Java: compilation and for runtime.

For compilation we saw sometimes differences in the produced bytecode for different minor version numbers. The bytecode should still expose the same runtime behavior.
Note that {user-manual}java_plugin.html#sec:java_compile_avoidance[Java compile avoidance] will treat this bytecode the same since it extracts the ABI.

Treating the minor number always as an input would it make very hard for developers to pull from the build cache. We saw that even in bigger companies different developers on the same team were using different Java minor versions. If you are able to control the environment in a way that everybody in your team and on CI is using exactly the same Java minor version then we suggest that you add the minor version as an input.

Note that even without tracking the Java minor version you may have cache misses for developers due to some locally compiled class files which constitute an input to test execution.
If these outputs made it into the local build cache on this developers machine even a clean will not solve this situation.
Therefore, the choice for tracking the Java minor version is between sometimes or never re-using outputs between for test execution between different Java minor versions.

Note that the compiler infrastructure provided by the JVM used to run Gradle is also used by the Groovy compiler.
Therefore, you can expect differences in the bytecode of compiled Groovy classes for the same reasons as above and the same suggestions apply.

=== Avoid changing inputs external to your build

If your build is dependent on external dependencies like binary artifacts or dynamic data from a web page you need to make sure that these inputs are consistent throughout your infrastructure.
When there are some variations between machines then there will be no cache hits.

Never re-release a non-changing binary dependency with the same version number but different contents: if this happens with a plugin dependency, you will never be able to explain why you don’t see cache reuse between machines (it’s because they have different versions of that artifact).

For changing binary dependencies you would need to pay attention whether the same dependency is used throughout your build pipeline.
You may want to look into the https://github.com/nebula-plugins/gradle-dependency-lock-plugin[dependency lock plugin] or switch to using {user-manual}composite_builds.html[composite builds] instead.

The same is true for depending on volatile external resources, for example a list of released versions.
One way of locking the changes would be to check in the volatile resource whenever it changes so that the builds only depend on the state in source control and not on the volatile resource itself.

=== Suggestions for authoring your build

==== Review usages of `doFirst`

Using `doFirst` from a build script on a cacheable tasks ties you to build script changes since the implementation of the closure comes from the build script.
If possible, you should use a separate tasks instead.

Modifying inputs or output properties via the runtime API in `doFirst` is discouraged since these changes will not be detected for up-to-date checks and the build cache.
Even worse, when the task does not execute then the configuration of the task is actually different from when it executes.
Instead of using `doFirst` for modifying the inputs consider using a separate tasks to configure the task under question - a so called configure task.
E.g., instead of doing

[source,groovy]
jar {
    doFirst {
        jar.manifest.mainAttributes('Class-Path': "${project(':core').jar.archivePath.name} ${project(':baseServices').jar.archivePath.name}")
    }
}

do

[source,groovy]
-------------------
task configureJar {
    doLast {
        jar.manifest.mainAttributes('Class-Path': "${project(':core').jar.archivePath.name} ${project(':baseServices').jar.archivePath.name}")
    }
}

jar.dependsOn(configureJar)
-------------------

[[logic_based_on_task_outcome]]
==== Build logic based on the outcome of a task

Do not base build logic on whether a task has been _executed_.
In particular you should not assume that the output of a task can only change if it did actually execute.
The outputs could have been loaded from the build cache, too.
In general, you should work together Gradle's up-to-date checks since this will ensure that task output caching has the same view of the task.
Using `outputs.upToDateWhen` is discouraged and should be better modelled by adding the right inputs to the task.

==== Overlapping outputs

If two tasks write to the same output directory or output file they cannot be cached and task output caching will be automatically disabled for the task.
Gradle's built-in tasks are configured in a way that there will not be any overlapping outputs.
When you add new tasks to your build or re-configure built-in tasks make sure you do not create overlapping outputs for cacheable tasks.
If you must you can add a `Sync` task which then would sync the merged outputs into the target directory while the original tasks remain cacheable.

Gradle Enterprise will show tasks where caching was disabled for overlapping outputs in the timeline.

image::overlapping-outputs-timeline.png[]

=== Volatile data in build artifacts

If you include timestamps or other volatile data like Git commit ids in task inputs or outputs then it will be difficult for Gradle to re-use these between builds.
We will go through different instances of volatile data and how to work around using the build cache anyway.

[[volatile_inputs]]
==== Volatile inputs

If you use a volatile input like a timestamp as an input property for a task, then there is nothing Gradle can do to make the task cacheable.
You should really think hard if the volatile data is really essential to the output or if it is only there for e.g. auditing purposes.

If the volatile input is essential to the output then you can try to make the task using the input cheaper to execute.
You can do this by splitting the task into two tasks - the first task doing the expensive work which is cacheable and the second task adding the volatile data to the output.
In this way the output stays the same and the build cache can be used to avoid doing the expensive work.
For example for building a jar file the expensive part - Java compilation - is already a different task while the jar task itself, which is not cacheable, is cheap.

If it is not an essential part of the output, then you should not declare it as an input.
As long as the volatile input does not influence the output then there is nothing else to do.
Most times though, the input will be part of the output.

[[volatile_outputs]]
==== Volatile outputs

Having tasks which generate different outputs for the same inputs can pose a challenge for the effective use of task output caching.
If the task output containing the volatile data is not used by any other task then the effect is very limited.
It basically means that pulling from the cache might produce a different result than executing the same task locally.
If the only difference between the outputs is a timestamp then you can either accept the effect of the build cache or decide that the task is not cacheable after all.

The story is different if an other task depend on the volatile outputs of a task.
For example, re-creating a jar file from the files with the same contents but different modification times yields a different jar file.
Any other task depending on this jar file as an input file could not be loaded from the cache when the jar file is rebuilt locally.
This can lead to hard to diagnose cache misses when the consuming build is not a clean build.
For example when doing incremental builds it is possible that the artifact on disk which is considered up-to-date and
the artifact in the build cache are different even though they are essentially the same.
A task depending on this task output would then not be able to load outputs from the build cache since the inputs are not exactly the same.

===== Input normalization

This is where {user-manual}more_about_tasks.html#sec:configure_input_normalization[input normalization] comes into play.
Input normalization is used by Gradle to determine if two task inputs are essentially the same.
Gradle compares normalized inputs when doing up-to-date checks and when determining the build cache key.
For a non-specialized input property Gradle doesn't do much - it looks at the content of the property or the files and compares those.

As soon as Gradle understands that the input is a runtime classpath it switches to a smarter behavior since the concept of a classpath is known to Gradle.
For example, for a runtime classpath Gradle inspects the contents of jar files and ignores the timestamps of the entries of the jar file.
This means that a rebuilt jar file would be considered the same runtime classpath input.
The details what level of understanding Gradle uses for detecting changes to classpath see the {user-manual}more_about_tasks.html#sec:task_input_using_classpath_annotations[userguide].

For a runtime classpath it is possible to provide better insights to Gradle which files are essential to the input by {user-manual}more_about_tasks.html#sec:configure_input_normalization[configuring input normalization].

Let's say you want to add a file `build-info.properties` to all your produced jar files which contains volatile information about the build, e.g. the timestamp when the build started or some ID to identify the CI job that published the artifact.
This file is only for auditing purposes, and has no effect on the outcome of running tests.
Nonetheless, this file is part of the runtime classpath for the `test` task and changes on every build invocation.
In order to benefit from task output caching again you can add the following configuration to your project.

[source,groovy]
normalization {
    runtimeClasspath {
        ignore "build-info.properties"
    }
}

The effect of this configuration would be that changes to `build-info.properties` would be ignored for up-to-date checks and build cache key calculations.
Note that this will not change the runtime behavior of the `test` task - i.e. any test is still able to load `build-info.properties` and the runtime classpath is still the same as before.

If input normalization doesn't provide the necessary features then you can also try to make the task reproduce the output byte per byte on each invocation.

===== Reproducible outputs

While input normalization provides a way to describe what is essential for the consumer of an artifact, reproducible outputs aim to solve the same problem on the producer side.
If possible, using input normalization should be the preferred way to address problems with volatile outputs.
Note that can be challenging to have tasks reproduce exactly the same byte per byte output for the same inputs.

For tar and zip files Gradle can be configured to create {user-manual}working_with_files#sec:reproducible_archives[reproducible archives].
This is done by configuring e.g. the `Zip` task via the following snippet.

[source,groovy]
-----------
task createZip(type: Zip) {
    preserveFileTimestamps = false
    reproducibleFileOrder = true
...
}
-----------

Another way to make the outputs reproducible is to activate caching for a task with volatile outputs.
If you can make sure that the same build cache is used for all builds then the task will always have the same outputs for the same inputs by design of the build cache.
Going down this road can lead to different problems with cache misses for incremental builds as described above.
Moreover, race conditions between different builds trying to store the same outputs in the build cache in parallel can lead to hard to diagnose cache misses.
If possible, you should avoid going down that route.

==== Limit the effect of volatile data

If none of the described solutions for dealing with volatile data work for you, you should still be able to limit the effect of volatile data on effective use of the build cache.
This can be done by adding the volatile data later to the outputs as described in [[volatile_inputs]].
Another option would be to move the volatile data so it affects less tasks.
For example moving the dependency from the `compile` to the `runtime` configuration may already have quite an impact.

Sometimes it is also possible to build two artifacts, one containing the volatile data and another one containing a constant representation of the volatile data.
The non-volatile output would be used e.g. for testing while the volatile one would be published to an external repository.
This is in conflict with the Continuous Delivery "build artifacts once" principle but can sometimes be the only option.

=== Custom and third party tasks

If your build contains custom or third party tasks, you should take special care that these don't influence the effectiveness of the build cache.
Special care should be taken for code generation tasks which may produce <<volatile_outputs>>.
This can happen if the code generator includes e.g. a timestamp in the generated files or depends on the order of the input files.
Other pitfalls can be the use of `HashMap`s or other data structures without order guarantees in the tasks code.

Note that some third party tasks can even influence cacheability of Gradle's built-in tasks.
This can happen if they add inputs like absolute paths or volatile data to Gradle's built-in tasks via the runtime API.
In the worst case this can lead to incorrect builds when the plugins try to depend on <<logic_based_on_task_outcome,outcome of a task>> and do not take `FROM-CACHE` into account.
